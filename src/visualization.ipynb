{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pablo Vicente Juan, Ming Zhou and Macrina Mar√≠a Lobo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pv2288, mz2591 and mml2204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Representation Learning With Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from helper.image_manipulation import transform, inverse_transform\n",
    "from helper.network_builder import build_discriminator, build_generator\n",
    "\n",
    "relu = T.nnet.relu\n",
    "tanh = T.tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_batch_x = np.load('../results/recons_test90.npy')\n",
    "train_batch_x = inverse_transform(train_batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(4, 4,  figsize=(10,10))\n",
    "for i in xrange(4):\n",
    "    for j in xrange(4):\n",
    "        plt.axes(axarr[i,j])\n",
    "        plt.imshow(train_batch_x[i+4*j].transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize intermediate outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image dimension\n",
    "n_channels = 3              # Number of channels in image\n",
    "img_size = 64               # Number of pixels width/height of images\n",
    "\n",
    "#Architecture parameters\n",
    "n_g_filters = 128           # Number of generator filters in first conv layer\n",
    "n_d_filters = 128           # Number of discriminator filters in first conv layer\n",
    "dimZ = 100                  # Number of dim for Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Theano variable for real images\n",
    "X = T.tensor4('X')\n",
    "# Theano variable for random noise vector\n",
    "Z = T.matrix('Z')\n",
    "\n",
    "# Generator architecture\n",
    "g_initial_im_size = 4\n",
    "g_flat_size = (dimZ, n_g_filters*8*4*4)\n",
    "g_layer_size = [n_g_filters*4, n_g_filters*2, n_d_filters, n_channels]\n",
    "g_num_filters = [n_g_filters*8, n_g_filters*4, n_d_filters*2, n_d_filters]\n",
    "g_filter_size = [5, 5, 5, 5]\n",
    "g_norm = [True, True, True, False]\n",
    "g_activation = [relu, relu, relu, tanh]\n",
    "g_subsample = [(2,2),(2,2),(2,2),(2,2)]\n",
    "g_border_mode = [(2,2),(2,2),(2,2),(2,2)]\n",
    "\n",
    "# Discriminator architecture\n",
    "d_layer_size = [n_channels, n_d_filters, n_d_filters*2, n_d_filters*4]\n",
    "d_num_filters = [n_d_filters, n_d_filters*2, n_d_filters*4, n_d_filters*8]\n",
    "d_filter_size = [5, 5, 5, 5]\n",
    "d_norm = [False, True, True, True]\n",
    "d_flat_size = (n_d_filters*8*4*4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cars, n_train_batches = load_dataset('../data/pokemon.npy', batch_size)\n",
    "datasetX = transform(datasetX)\n",
    "\n",
    "discrim_params = pickle.load( open( \"../discrim_params.p\", \"rb\" ) )\n",
    "gen_params = pickle.load( open( \"../gen_params.p\", \"rb\" ) )\n",
    "sample_zmb = pickle.load( open( \"../sample_zmb.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build generator\n",
    "gX, g_layers = build_generator(Z, g_layer_size, g_num_filters, g_filter_size, g_flat_size, \n",
    "                               g_subsample, g_border_mode, g_norm, g_activation, g_initial_im_size, \n",
    "                               gen_params)\n",
    "\n",
    "# Build discriminator for real samples\n",
    "p_real, d_real_layers = build_discriminator(X, d_layer_size, d_num_filters, d_filter_size, \n",
    "                                            d_flat_size, d_norm, discrim_params)\n",
    "\n",
    "# Build discriminator for generated samples\n",
    "p_gen, d_gen_layers = build_discriminator(gX, d_layer_size, d_num_filters, d_filter_size, \n",
    "                                          d_flat_size, d_norm, discrim_params)\n",
    "\n",
    "_gen = theano.function([Z], gX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build funtion to explore intermediate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_gen = theano.function([Z], gX)\n",
    "\n",
    "d_layer0 = theano.function([X], d_real_layers[0].output)\n",
    "d_layer1 = theano.function([X], d_real_layers[1].output)\n",
    "d_layer2 = theano.function([X], d_real_layers[2].output)\n",
    "d_layer3 = theano.function([X], d_real_layers[3].output)\n",
    "d_layer4 = theano.function([X], d_real_layers[4].output)\n",
    "\n",
    "g_layer0 = theano.function([Z], g_layers[0].output)\n",
    "g_layer1 = theano.function([Z], g_layers[1].output)\n",
    "g_layer2 = theano.function([Z], g_layers[2].output)\n",
    "g_layer3 = theano.function([Z], g_layers[3].output)\n",
    "g_layer4 = theano.function([Z], g_layers[4].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = g_layer1(sample_zmb)\n",
    "print(out.shape)\n",
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(16, 16,  figsize=(10,10))\n",
    "print(k)\n",
    "for i in xrange(16):\n",
    "    for j in xrange(16):\n",
    "        plt.axes(axarr[i,j])\n",
    "        plt.imshow(out[i+4*j][k], interpolation='nearest')\n",
    "        plt.axis('off')    \n",
    "k += 16        \n",
    "plt.savefig('g_layer1_output.png', bbox_inches='tight')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximal output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is based on\n",
    "\n",
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_index = 0  \n",
    "\n",
    "# build a loss function that maximizes the activation\n",
    "# of the nth filter of the layer considered\n",
    "layer_output = g_layers[-1].output\n",
    "loss = T.mean(layer_output[:, filter_index, :, :])\n",
    "\n",
    "# compute the gradient of the input picture wrt this loss\n",
    "grads = T.grad(loss, g_layers[0].input)[0]\n",
    "\n",
    "# normalization trick: we normalize the gradient\n",
    "grads /= (T.sqrt(T.mean(T.square(grads))) + 1e-5)\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = theano.function([Z], [loss, grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we start from a gray image with some noise\n",
    "img_width = 64\n",
    "img_height = 64\n",
    "#input_img_data = np.random.random((1, 3, img_width, img_height)) * 20 + 128.\n",
    "#input_img_data = input_img_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run gradient ascent for 20 steps\n",
    "for i in range(20):\n",
    "    loss_value, grads_value = iterate(first_sample)\n",
    "    first_sample += grads_value * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(8, 8,  figsize=(10,10))\n",
    "print(k)\n",
    "for i in xrange(8):\n",
    "    for j in xrange(8):\n",
    "        plt.axes(axarr[i,j])\n",
    "        img = input_img_data[i+8*j]\n",
    "        img = deprocess_image(img)\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        plt.axis('off')    \n",
    "\n",
    "#plt.savefig('d_layer3_output.png', bbox_inches='tight')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
